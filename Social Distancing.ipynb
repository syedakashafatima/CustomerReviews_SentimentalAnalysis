{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecfab594",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Social Distancing Project using YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b65f6f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import ImageTk, Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd56b268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Social Distancing\")\n",
    "\n",
    "    # Set the window size and make it non-resizable\n",
    "    root.geometry(\"500x500\")\n",
    "    root.resizable(False, False)\n",
    "\n",
    "    # Load the background image\n",
    "    bg_image = Image.open(\"social.jpg\")\n",
    "    bg_photo = ImageTk.PhotoImage(bg_image)\n",
    "\n",
    "    # Create a label to hold the background image\n",
    "    bg_label = tk.Label(root, image=bg_photo)\n",
    "    bg_label.place(x=0, y=0, relwidth=1, relheight=1)\n",
    "\n",
    "    # Create a label for the welcome message\n",
    "    welcome_label = tk.Label(root, text=\"Welcome to Social Distance Indicator\", font=(\"Arial\", 16, \"bold\"))\n",
    "    welcome_label.pack(pady=20)\n",
    "\n",
    "    def run_social_distance_detector():\n",
    "        file_path = filedialog.askopenfilename(filetypes=[(\"Video Files\", \"*.mp4\")])\n",
    "        if file_path:\n",
    "            \n",
    "            # Load the YOLO weights and configuration\n",
    "            # 'yolov3.weights' contains pre trained weights of NN\n",
    "            # 'yolov3.cfg' contains network configuration\n",
    "            net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "            net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "            net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "            distance_thres = 50\n",
    "            \n",
    "            # Open the video file for reading\n",
    "            cap = cv2.VideoCapture(file_path)\n",
    "            \n",
    "            def dist(pt1,pt2):\n",
    "                try:\n",
    "                    # calculates Euclidean distance\n",
    "                    return ((pt1[0]-pt2[0])**2 + (pt1[1]-pt2[1])**2)**0.5\n",
    "                except:\n",
    "                    return\n",
    "                \n",
    "            # retrieves the names of all the layers in the neural network model 'net'\n",
    "            layer_names = net.getLayerNames()\n",
    "            # indentifies the output layer and retrieves the names of the layers corresponding \n",
    "            # to the unconnected output layers by subtracting 1 from each index\n",
    "            output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "            #print name of the output layer\n",
    "            print('Output layers',output_layers)\n",
    "            # Read the first frame from the video\n",
    "            _,frame = cap.read()\n",
    "            \n",
    "            # Create a VideoWriter object to save the output video\n",
    "            fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "            writer = cv2.VideoWriter('output.avi', fourcc, 30,(frame.shape[1], frame.shape[0]), True)\n",
    "\n",
    "            ret = True\n",
    "            while ret:\n",
    "                # Read the next frame from the video\n",
    "                ret, img = cap.read()\n",
    "                if ret:\n",
    "                    height, width = img.shape[:2]\n",
    "                    \n",
    "                    # Preprocess the image for input to the neural network\n",
    "                    blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "                    net.setInput(blob)\n",
    "                    outs = net.forward(output_layers)\n",
    "                    confidences = []\n",
    "                    boxes = []\n",
    "                    \n",
    "                     # Process each detected object in the output\n",
    "                    for out in outs:\n",
    "                        # iterates over each element within out, representing a specific detection within the image\n",
    "                        for detection in out:\n",
    "                            # extracts the scores which represent the confidence of the model \n",
    "                            scores = detection[5:]\n",
    "                            # finds the index of the highest score \n",
    "                            class_id = np.argmax(scores)\n",
    "                            if class_id!=0:\n",
    "                                continue\n",
    "                            confidence = scores[class_id]\n",
    "                                #checks if thres is above 0.3 of the selected class\n",
    "                            if confidence > 0.3:\n",
    "                                # creates bounding boxes\n",
    "                                center_x = int(detection[0] * width)\n",
    "                                center_y = int(detection[1] * height)\n",
    "                                w = int(detection[2] * width)\n",
    "                                h = int(detection[3] * height)\n",
    "                                x = int(center_x - w / 2)\n",
    "                                y = int(center_y - h / 2)\n",
    "                                boxes.append([x, y, w, h])\n",
    "                                confidences.append(float(confidence))\n",
    "                    \n",
    "                    # Apply non-maximum suppression based on the confidence score to remove redundant overlapping boxes\n",
    "                    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "                    persons = []\n",
    "                    person_centres = []\n",
    "                    violate = set()\n",
    "                    # Iterate over the remaining boxes after non-maximum suppression\n",
    "                    for i in range(len(boxes)):\n",
    "                        if i in indexes:\n",
    "                            x,y,w,h = boxes[i]\n",
    "                            persons.append(boxes[i])\n",
    "                            person_centres.append([x+w//2,y+h//2])\n",
    "                    # Check for social distancing violations\n",
    "                    for i in range(len(persons)):\n",
    "                        for j in range(i+1,len(persons)):\n",
    "                            if dist(person_centres[i],person_centres[j]) <= distance_thres:\n",
    "                                violate.add(tuple(persons[i]))\n",
    "                                violate.add(tuple(persons[j]))\n",
    "        \n",
    "                    v = 0\n",
    "                    for (x,y,w,h) in persons:\n",
    "                        if (x,y,w,h) in violate:\n",
    "                            color = (0,0,255)\n",
    "                            v+=1\n",
    "                        else:\n",
    "                            color = (0,255,0)\n",
    "                        cv2.rectangle(img,(x,y),(x+w,y+h),color,2)\n",
    "                        cv2.circle(img,(x+w//2,y+h//2),2,(0,0,255),2)\n",
    "                    cv2.putText(img,'No of Violations : '+str(v),(15,frame.shape[0]-10),cv2.FONT_HERSHEY_SIMPLEX,1,(0,126,255),2)\n",
    "                    writer.write(img)\n",
    "                    cv2.imshow(\"Result\", img)\n",
    "    \n",
    "                if cv2.waitKey(1) == 27:\n",
    "                    break\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "            \n",
    "\n",
    "    # Create a frame to hold the welcome message and the button\n",
    "    frame = tk.Frame(root)\n",
    "    frame.place(relx=0.5, rely=0.5, anchor=tk.CENTER)\n",
    "\n",
    "    # Create a button to select and run the social distance detection on the video file\n",
    "    detect_button = tk.Button(frame, text=\"Select and Run Social Distance Detector\", command=run_social_distance_detector, padx=10, pady=5, fg=\"white\", bg=\"blue\", font=(\"Arial\", 12, \"bold\"))\n",
    "    detect_button.pack()\n",
    "\n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80925a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a393c60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
